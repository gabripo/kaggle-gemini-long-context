{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tender2Project\nThe following Kaggle notebook exploits the long context window of Gemini, in order to fulfill the following targets:\n- Analyze the tender for a project.\n- Analyze the information about possible products, provided from different companies.\n- Find the best combination of products to build the project in the tender, identifying the most compliant company as well.\n\n## Notebook structure\nThe notebook is composed by different parts, each one with a specific target:\n- A tender for a project is parsed, such that its information is converted to text.\n- Information scraped from the websites of different companies is loaded as text.\n- All the text is forwarded to Gemini, whereas a system prompt and a user prompt are written to explain the purposed o Gemini.\n\n## Theoretical aspects\nThe current way to use Gemini makes use of the following properties of a LLM (Large Language Model) like Gemini:\n|  **LLM property** | **Where it is used** | **How it is used** |\n|:-----------------:|:--------------------:|:------------------:|\n|     Reasoning     |          TBD         |         TBD        |\n|       Memory      |          TBD         |         TBD        |\n| Chain of Thoughts |          TBD         |         TBD        |\n|                   |                      |                    |","metadata":{}},{"cell_type":"markdown","source":"Clean the working directory","metadata":{}},{"cell_type":"code","source":"! rm -r /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:07.863660Z","iopub.execute_input":"2024-11-23T09:27:07.864064Z","iopub.status.idle":"2024-11-23T09:27:08.870088Z","shell.execute_reply.started":"2024-11-23T09:27:07.864032Z","shell.execute_reply":"2024-11-23T09:27:08.868850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Markdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:08.872622Z","iopub.execute_input":"2024-11-23T09:27:08.872910Z","iopub.status.idle":"2024-11-23T09:27:08.877781Z","shell.execute_reply.started":"2024-11-23T09:27:08.872882Z","shell.execute_reply":"2024-11-23T09:27:08.876820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the tenders","metadata":{}},{"cell_type":"markdown","source":"Locate the tenders - in PDF format.","metadata":{}},{"cell_type":"code","source":"# fetch the script to download content from GitHub\n!wget https://raw.githubusercontent.com/gabripo/kaggle-gemini-long-context/refs/heads/main/github_downloader.py -P /kaggle/working/scripts\n\n# add downloaded script to the Python path\nimport sys\nsys.path.append('/kaggle/working/scripts')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:08.878934Z","iopub.execute_input":"2024-11-23T09:27:08.879161Z","iopub.status.idle":"2024-11-23T09:27:10.085013Z","shell.execute_reply.started":"2024-11-23T09:27:08.879138Z","shell.execute_reply":"2024-11-23T09:27:10.084089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import github_downloader\n\ngithub_downloader.download_files_from_github_repo(folderName=\"tenders\", saveFolder=\"/kaggle/working/tenders\", extension=\"pdf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:10.086307Z","iopub.execute_input":"2024-11-23T09:27:10.086620Z","iopub.status.idle":"2024-11-23T09:27:10.644146Z","shell.execute_reply.started":"2024-11-23T09:27:10.086576Z","shell.execute_reply":"2024-11-23T09:27:10.643158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# if the PDF file is given as Kaggle Input (for example, manually uploaded), change the use_kaggle_input to True\nuse_kaggle_input_tender = False if os.path.exists('/kaggle/working/tenders') else True\nif use_kaggle_input_tender:\n    tenders_file_path = '/kaggle/input/tenders'\nelse:\n    tenders_file_path = '/kaggle/working/tenders'\n\nprint(f\"The folder {tenders_file_path} will be considered as containing the tenders\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:10.646831Z","iopub.execute_input":"2024-11-23T09:27:10.647119Z","iopub.status.idle":"2024-11-23T09:27:10.652506Z","shell.execute_reply.started":"2024-11-23T09:27:10.647088Z","shell.execute_reply":"2024-11-23T09:27:10.651609Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Installing required Python packages to analyze the tender - in PDF format.","metadata":{}},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:10.653798Z","iopub.execute_input":"2024-11-23T09:27:10.654077Z","iopub.status.idle":"2024-11-23T09:27:18.784848Z","shell.execute_reply.started":"2024-11-23T09:27:10.654045Z","shell.execute_reply":"2024-11-23T09:27:18.783955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Extract information from the tenders.\nThe output will be a text.","metadata":{}},{"cell_type":"code","source":"import os\nfrom PyPDF2 import PdfReader\n\ntenders = [t for t in os.listdir(tenders_file_path) if t.endswith(\".pdf\")]\ntenders_info = {}\nfor tender in tenders:\n    print(f\"Reading the tender {tender} ...\")\n    reader = PdfReader(os.path.join(tenders_file_path, tender))\n\n    tenders_info[tender] = {}\n    tenders_info[tender][\"name\"] = tender\n    tenders_info[tender][\"content\"] = \"\\n\".join([page.extract_text() for page in reader.pages])\n\n# information for each tender can be accessed by:\n# tenders_info[tenders[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:18.786274Z","iopub.execute_input":"2024-11-23T09:27:18.787218Z","iopub.status.idle":"2024-11-23T09:27:20.219559Z","shell.execute_reply.started":"2024-11-23T09:27:18.787170Z","shell.execute_reply":"2024-11-23T09:27:20.218602Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fetch information about companies","metadata":{}},{"cell_type":"markdown","source":"## Overview\nInformation about interesting companies is obtained from their websites.\n\nTo generate data out of the companies' websites, we implemented a crawler.\nThe final output of the crawler is a JSON file, in which each field refers to a company: for each company, all the information of the websites is merged.\n\n> To make things easier, the mentioned JSON file will be fetched from a Git repository where the crawling function has already been executed.\n\n## Details about the crawling process:\n- **Recursive scan**: after a webpage is scanned and its content is stored, eventual found sublinks are scanned, as well. A limit of the wepages to download is given as input.\n- **Redundant information is deleted**: if some website content can be found multiple times in all the webpages of one company, then it is skipped. *Example*: undesired and redundant lines like \"Contact Us\" are removed, ensuring that the final content does not include unnecessary sentences.\n- **Caching of already downloaded pages**: for each webpage, the content is stored in a JSON file, as well as the found sublinks. *Example*: after a run with a limit of N pages, other runs with less than N pages will use the stored files instead downloading data from internet; at the contrary, if the limit is increased to M > N pages, only M - N additional pages will be downloaded while the first N pages will be taken from the stored file.","metadata":{}},{"cell_type":"markdown","source":"## Load the results from the crawler's repo","metadata":{}},{"cell_type":"code","source":"github_downloader.download_files_from_github_repo(folderName=\"\", saveFolder=\"/kaggle/working/companies_info\", extension=\"json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:20.220636Z","iopub.execute_input":"2024-11-23T09:27:20.220911Z","iopub.status.idle":"2024-11-23T09:27:20.669184Z","shell.execute_reply.started":"2024-11-23T09:27:20.220884Z","shell.execute_reply":"2024-11-23T09:27:20.668318Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Locate the JSON file containing the companies' information.","metadata":{}},{"cell_type":"code","source":"import os\n\n# if the JSON file is given as Kaggle Input (for example, manually uploaded), change the use_kaggle_input to True\nuse_kaggle_input_companies = False if os.path.exists('/kaggle/working/companies_info') else True\ncompanies_json_name = 'companies_info.json'\nif use_kaggle_input_companies:\n    companies_info_file_path = os.path.join('/kaggle/input/companies-info', companies_json_name)\nelse:\n    companies_info_file_path = os.path.join('/kaggle/working/companies_info', companies_json_name)\n\nprint(f\"The file {companies_info_file_path} will be used for the information regarding the companies\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:20.670368Z","iopub.execute_input":"2024-11-23T09:27:20.671165Z","iopub.status.idle":"2024-11-23T09:27:20.676490Z","shell.execute_reply.started":"2024-11-23T09:27:20.671121Z","shell.execute_reply":"2024-11-23T09:27:20.675625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define a small function to read the information about the companies - in JSON format.","metadata":{}},{"cell_type":"code","source":"import json\n\ndef read_json_info(jsonFilePath: str) -> dict:\n    if os.path.exists(jsonFilePath):\n        with open(jsonFilePath, \"r\") as f:\n            data = json.load(f)\n        return data\n    else:\n        return {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:20.677790Z","iopub.execute_input":"2024-11-23T09:27:20.678133Z","iopub.status.idle":"2024-11-23T09:27:20.687470Z","shell.execute_reply.started":"2024-11-23T09:27:20.678095Z","shell.execute_reply":"2024-11-23T09:27:20.686696Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the companies' information by using the defined function.","metadata":{}},{"cell_type":"code","source":"companies_info = read_json_info(companies_info_file_path)\n\n# companies_info is a dictionary, where the key is the name of the company and the related value its information\n# print(companies_info[\"SIEMENS\"]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:20.688472Z","iopub.execute_input":"2024-11-23T09:27:20.688740Z","iopub.status.idle":"2024-11-23T09:27:20.736195Z","shell.execute_reply.started":"2024-11-23T09:27:20.688715Z","shell.execute_reply":"2024-11-23T09:27:20.735279Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Chat with Gemini","metadata":{}},{"cell_type":"code","source":"# API key got here: https://ai.google.dev/tutorials/setup\n\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n\nuser_secrets = UserSecretsClient()\nsecret_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n\ngenai.configure(api_key = secret_key)\n\nmodel_name = 'gemini-1.5-flash-latest'\nmodel = genai.GenerativeModel(model_name=model_name)\n\nchat = model.start_chat()\n\nmodel_info = genai.get_model(f\"models/{model_name}\")\nprint(f\"{model_info.input_token_limit=}\")\nprint(f\"{model_info.output_token_limit=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:20.737221Z","iopub.execute_input":"2024-11-23T09:27:20.737465Z","iopub.status.idle":"2024-11-23T09:27:21.297001Z","shell.execute_reply.started":"2024-11-23T09:27:20.737442Z","shell.execute_reply":"2024-11-23T09:27:21.296090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyze all the tenders","metadata":{}},{"cell_type":"code","source":"download_tenders_json_from_repo = True # switch to False if willing to generate the json file within this notebook\n\nif download_tenders_json_from_repo:\n    # this helps reducing the Gemini Quota, since no queries will be performed for the tenders\n    github_downloader.download_files_from_github_repo(folderName=\"tenders\", saveFolder=tenders_file_path, extension=\"json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.297929Z","iopub.execute_input":"2024-11-23T09:27:21.298162Z","iopub.status.idle":"2024-11-23T09:27:21.526731Z","shell.execute_reply.started":"2024-11-23T09:27:21.298139Z","shell.execute_reply":"2024-11-23T09:27:21.525942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tender_prompt_template = \"The document you have is a tender, that contains technical requirements for a project. Summarize the technical requirements. The content of the document is: \"\ntender_prompts = []\nfor info in tenders_info.values():\n    tender_prompts.append(f\"You have a document called {info['name']} . \" + tender_prompt_template + f\"{info['content']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.529279Z","iopub.execute_input":"2024-11-23T09:27:21.529526Z","iopub.status.idle":"2024-11-23T09:27:21.534179Z","shell.execute_reply.started":"2024-11-23T09:27:21.529501Z","shell.execute_reply":"2024-11-23T09:27:21.533119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from time import sleep\n\nresponses = {}\ntenders_json_file_path = os.path.join(tenders_file_path, 'tenders.json')\nif os.path.exists(tenders_json_file_path):\n    responses = read_json_info(tenders_json_file_path)\n    print(f\"Responses loaded from file {tenders_json_file_path}\")\nelse:\n    num_queries = 0\n    for tender_prompt, tender_name in zip(tender_prompts, tenders):\n        print(f\"Generating response for tender {tender_name} ...\")\n        response = chat.send_message(tender_prompt)\n        # print(response.text)\n        responses[tender_name] = {'prompt': tender_prompt, 'answer': response.text}\n        print(f\"Response for tender {tender_name} generated.\")\n\n        num_queries += 1\n        \"\"\"\n        if num_queries % 2 == 0:\n            wait_time_seconds = 90\n            print(f\"Waiting {wait_time_seconds} before continuing, to not exceed Gemini's quota\")\n            sleep(wait_time_seconds)\n        \"\"\"\n\n    with open(tenders_json_file_path, 'w') as f:\n        json.dump(responses, f, ensure_ascii=True, indent=4)\n    print(f\"Responses stored into {tenders_json_file_path}\")\n\nprint(\"Analysis of the tenders concluded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.535198Z","iopub.execute_input":"2024-11-23T09:27:21.535457Z","iopub.status.idle":"2024-11-23T09:27:21.546886Z","shell.execute_reply.started":"2024-11-23T09:27:21.535432Z","shell.execute_reply":"2024-11-23T09:27:21.546101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# example how to include the chat history here https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_chat.ipynb\n# description of the Content class here https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai/GenerativeModel.md\nfrom google.generativeai.protos import Content, Part\n\nhistory_chat = []\nfor idx_response, response in enumerate(responses.values()):\n    query = Part()\n    query.text = response['prompt']\n    # TODO: consider different users? Example: for the tender number idx_response, use f\"user_{idx_response}\"\n    history_chat.append(Content(role=\"user\", parts=[query]))\n\n    answer = Part()\n    answer.text = response['answer']\n    history_chat.append(Content(role=\"model\", parts=[answer]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.547848Z","iopub.execute_input":"2024-11-23T09:27:21.548155Z","iopub.status.idle":"2024-11-23T09:27:21.561226Z","shell.execute_reply.started":"2024-11-23T09:27:21.548129Z","shell.execute_reply":"2024-11-23T09:27:21.560489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the system and user prompts","metadata":{}},{"cell_type":"code","source":"system_prompt = \"You are an experienced technical sales manager. You are given the full portfolio for products and solutions of companies, through their website. Use this information to provide detailed technical answers based on the tender requirements which were given to you.\"\n\nMarkdown(system_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.562194Z","iopub.execute_input":"2024-11-23T09:27:21.562534Z","iopub.status.idle":"2024-11-23T09:27:21.577666Z","shell.execute_reply.started":"2024-11-23T09:27:21.562495Z","shell.execute_reply":"2024-11-23T09:27:21.576784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_prompt = f\"\"\"\n\n1. Identify all the technical requirements in the tenders' information you have.\n\n2. For company [SIEMENS] and [HITACHI], find the respective relevant products and solutions with respect to point 1. Do this one company at a time and store the results.\n\n3. Calculate an affinity score in percentage of company [SIEMENS] and [HITACHI] based on the match of results in point 2. Explain the way how you computed this percentage.\n\nSIEMENS: {companies_info[\"SIEMENS\"]}\nHITACHI: {companies_info[\"HITACHI\"]}\n\n4. Return a quick technical summary of the tender.\n\n5. Return the technical details of the company with the highest affinity score and its score. Focus on the technical specifications mentioning the compliances with the tender. Report also the URL of the source where you found the informations and mention if there is some non compliant requirements from tender.\n\n6. Return also the other affinity scores alone of the other companies. \n\n\"\"\"\n\n# Markdown(user_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.578637Z","iopub.execute_input":"2024-11-23T09:27:21.578960Z","iopub.status.idle":"2024-11-23T09:27:21.592335Z","shell.execute_reply.started":"2024-11-23T09:27:21.578928Z","shell.execute_reply":"2024-11-23T09:27:21.591744Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test the history","metadata":{}},{"cell_type":"code","source":"chat_with_memory_temp = model.start_chat(history=history_chat)\nresponse_temp = chat_with_memory_temp.send_message(\"What are the tenders you have about?\")\n\nMarkdown(response_temp.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:21.593276Z","iopub.execute_input":"2024-11-23T09:27:21.593493Z","iopub.status.idle":"2024-11-23T09:27:24.858337Z","shell.execute_reply.started":"2024-11-23T09:27:21.593465Z","shell.execute_reply":"2024-11-23T09:27:24.857398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Count the needed tokens","metadata":{}},{"cell_type":"code","source":"print(f\"{model.count_tokens(history_chat)=}\")\nprint(f\"{model.count_tokens(system_prompt + user_prompt)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:24.859663Z","iopub.execute_input":"2024-11-23T09:27:24.860466Z","iopub.status.idle":"2024-11-23T09:27:30.514630Z","shell.execute_reply.started":"2024-11-23T09:27:24.860420Z","shell.execute_reply":"2024-11-23T09:27:30.513734Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate a response with chat history","metadata":{}},{"cell_type":"code","source":"chat_with_memory = model.start_chat(history=history_chat)\n\nprint(\"Providing prompts based on the previous analysis of the tenders ...\")\nresponse = chat_with_memory.send_message(f\"{system_prompt + user_prompt}\")\n# print(response.text)\nresponses['main_query'] = {'prompt': system_prompt + user_prompt, 'answer': response.text}\n\nprint(\"Response to the prompts is ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:27:30.515782Z","iopub.execute_input":"2024-11-23T09:27:30.516137Z","iopub.status.idle":"2024-11-23T09:28:12.030751Z","shell.execute_reply.started":"2024-11-23T09:27:30.516098Z","shell.execute_reply":"2024-11-23T09:28:12.029329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Markdown(responses['main_query']['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:28:12.034315Z","iopub.status.idle":"2024-11-23T09:28:12.034967Z","shell.execute_reply.started":"2024-11-23T09:28:12.034693Z","shell.execute_reply":"2024-11-23T09:28:12.034717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}