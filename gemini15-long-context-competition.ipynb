{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e6dd03",
   "metadata": {
    "papermill": {
     "duration": 0.006632,
     "end_time": "2024-11-24T12:32:21.324185",
     "exception": false,
     "start_time": "2024-11-24T12:32:21.317553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tender2Project\n",
    "The following Kaggle notebook exploits the long context window of Gemini, in order to fulfill the following targets:\n",
    "- Analyze technical and commercial tenders for a project.\n",
    "- Analyze the compatibility of products and solution of certain companies with respect to the tender documentations.\n",
    "- Find the best company and combination of products and services to build the project, generating a clause by clause report with compliant and not-compliant specifications.\n",
    "\n",
    "## Notebook structure\n",
    "The notebook is composed by different parts, each one with a specific target:\n",
    "- Tenders for a project are parsed, such that their information is converted to text.\n",
    "- Information scraped from the websites of different companies is loaded as text.\n",
    "- All the text is forwarded to Gemini in different prompts: combining multi-agent reasoning, chain of toughts and in-chat memory.\n",
    "\n",
    "## Multi-agent reasoning\n",
    "Multi-agent reasoning is applied in the code through the segmentation of tasks and the delegation of specific responsibilities to distinct roles. For example:\n",
    "\n",
    "Technical and Commercial Tender Agents: Separate prompts (tender_prompt_template_technical and tender_prompt_template_commercial) are used to guide the technical tender engineer and the commercial tender manager roles, respectively. Each agent has distinct objectives: identifying and summarizing technical or commercial requirements within tenders. This multi-agent structure ensures detailed and domain-specific analyses.\n",
    "\n",
    "A distinct prompt is also prepared for analyzing companies (e.g., SIEMENS and HITACHI) to match tender requirements with their products and solutions (get_response_companies_info). This allows tailored reasoning for comparing affinity between tenders and company offerings.\n",
    "\n",
    "## Chain of Thoughts\n",
    "The chain of thoughts approach is used to decompose complex tasks into sequential, step-by-step actions, ensuring methodical problem-solving. \n",
    "In both technical and commercial prompts we used phrases like \"Think step by step\" to guide the agent toward incremental reasoning. This ensures that requirements are dissected and analyzed in detail.\n",
    "The user prompt specifies a structured approach to calculating an affinity score, prompting the agent to explicitly explain the calculation process.\n",
    "Finally in the Clause-by-Clause Analysis, the final prompt directs the agent to meticulously compare tender requirements with company specifications, maintaining a clear progression in thought.\n",
    "This approach is embedded in the query processing of tenders and the affinity scoring logic in user_prompt_match and final_prompt, encouraging logical progression in the analysis.\n",
    "\n",
    "## In-chat memory\n",
    "The code utilizes in-chat memory to maintain conversational context across multiple interactions. This functionality is facilitated by Chat History Preservation: The function add_history_to_chat appends user queries and model responses (e.g., for tenders or company analyses) to history_chat. This ensures continuity, enabling the model to refer back to previous inputs and outputs during subsequent exchanges.\n",
    "Additionally, prompts such as system_prompt and user_prompt leverage the accumulated chat history to enhance the depth and relevance of responses. For example, when computing affinity scores or performing a clause-by-clause analysis, the model can reference earlier content in the chat_with_memory object. This allows a continous improvement of the prompt and on the information stored in the chat.\n",
    "\n",
    "\n",
    "\n",
    "## Conclusion for use case\n",
    "Using a long context window instead of Retrieval-Augmented Generation (RAG) for the selected use case was particularly beneficial due to the nature of the task, which involves reasoning across interdependent documents, maintaining conversational continuity, and ensuring consistent context for decision-making. \n",
    "In fact, in the past, we implemented a multi-agent framework using LangChain and OpenAI, where each company was represented by a dedicated agent. The repo is publicily availbla at https://github.com/SecchiAlessandro/LumadaAI. This framework was designed with a supervisor agent that dynamically routed user queries to the most relevant company-specific agent based on the query context. While innovative for that time, this approach encountered several challenges, particularly in stability, accuracy, and efficiency, making the current solution implemented in the notebook a more effective alternative. \n",
    "As the agents are operating independently, it was also difficult to generate combined solutions from different companies.\n",
    "Moreover, for each query, the supervisor had to perform an additional step of reasoning before invoking an agent.\n",
    "If the query was relevant to multiple agents, the framework had to perform multiple sequential calls, compounding the latency.\n",
    "\n",
    "The current solution with a centralized reasoning, ensure consistent application of logic and context.\n",
    "By avoiding the intermediate step of agent selection, it directly processes queries with a unified context, significantly reducing latency.\n",
    "\n",
    "The unified context allows the model to cross-reference tender requirements and company offerings directly, ensuring a cohesive and accurate analysis.\n",
    "This is particularly advantageous for tasks like affinity scoring, which require simultaneous consideration of multiple data points.\n",
    "\n",
    "The notebook’s approach scales better for handling multiple queries simultaneously, as it avoids the bottleneck of sequential agent calls. In fact, for new tender projects, it is just required to update the in-chat memory and to add new prompts for adding new in-chat agents.\n",
    "\n",
    "\n",
    "In summary, why we decided to implement tender2project?\n",
    "\n",
    "1. Holistic Context Retention\n",
    "Long Context Window: By storing the entire history of tender analyses (both technical and commercial) and company product evaluations, the model retains a comprehensive understanding of all previously provided information. This holistic context allows the model to reason about how specific requirements and offerings interrelate across multiple prompts.\n",
    "In RAG, the system retrieves only the most relevant chunks of information from the documents for each query. While efficient, this approach can fragment the analysis when tasks require synthesizing insights across documents, potentially leading to overlooked interconnections.\n",
    "2. Interdependent Analysis\n",
    "Tender and Company Matching: The task involves comparing multiple tenders against products and solutions offered by different companies, followed by calculating an affinity score and conducting a clause-by-clause compliance analysis. These steps require information from previous steps to be accessible and integrated seamlessly.\n",
    "RAG typically retrieves context independently for each query, which might result in loss of nuance or context-dependent reasoning, especially when relationships between multiple documents must be preserved. A long context window ensures the model has immediate access to the entire conversational flow and insights developed so far.\n",
    "3. Dynamic Multi-Agent Collaboration\n",
    "Role-Based Prompts: By maintaining a long context, the system can simulate multi-agent collaboration, where outputs from technical engineers, commercial managers, and sales managers flow into a unified reasoning framework.\n",
    "In RAG, each role’s analysis would require re-retrieving relevant information from documents, potentially leading to inconsistencies or duplications. With a long context window, outputs from one role naturally inform others, creating a seamless chain of thought.\n",
    "4. Reduced Query Overhead\n",
    "Fewer Retrievals, Continuous Focus: Long context windows reduce the need for multiple retrieval calls, making the process more efficient in scenarios where information is revisited or refined iteratively.\n",
    "RAG introduces latency and computational costs because each query requires searching and ranking document chunks. A long context window allows for continuous focus on the task, with all prior exchanges readily available.\n",
    "5. Affinity Score Calculation\n",
    "Global Context for Consistent Metrics: Computing an affinity score across companies for tenders requires integrating technical and commercial analysis alongside company data. This step benefits significantly from the model’s ability to access all previous responses simultaneously.\n",
    "In RAG, affinity scoring would require separate retrievals of technical requirements, commercial requirements, and company data for each tender. This could introduce discrepancies if context for one query is inadvertently excluded during retrieval.\n",
    "6. Clause-by-Clause Compliance Analysis\n",
    "Integrated Insight Application: Clause-by-clause analysis relies on cross-referencing previously extracted requirements with company offerings. The long context window allows the model to directly reference earlier inputs and outputs without reloading or retrieving.\n",
    "RAG retrievals for clause-by-clause analysis might lead to inconsistencies if prior reasoning is split across multiple retrievals. A long context window ensures the model \"remembers\" and applies earlier analyses cohesively.\n",
    "Trade-offs and Use Case Fit\n",
    "\n",
    "## Conclusion\n",
    "The centralized, long context window approach provides clear advantages in stability, response time, and accuracy over the earlier multi-agent framework. It highlights the importance of selecting a system architecture that aligns with the specific demands of the use case, particularly for complex, multi-faceted analyses like those in tender evaluations, clause-by-clause generation and company affinity scoring.\n",
    "#### The long context window acts as a shared workspace, recording and making all agent outputs accessible for seamless and holistic reasoning. In today's interconnected world, where partnerships and synergies are essential to addressing complex challenges, we envision a tool that enables continuous reasoning, uncovers new patterns and solutions, and minimizes the fragmentation of insights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f746552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:21.337813Z",
     "iopub.status.busy": "2024-11-24T12:32:21.337482Z",
     "iopub.status.idle": "2024-11-24T12:32:21.344917Z",
     "shell.execute_reply": "2024-11-24T12:32:21.344289Z"
    },
    "papermill": {
     "duration": 0.015496,
     "end_time": "2024-11-24T12:32:21.346471",
     "exception": false,
     "start_time": "2024-11-24T12:32:21.330975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import Python libraries\n",
    "import os\n",
    "import json\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a6a052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:21.358301Z",
     "iopub.status.busy": "2024-11-24T12:32:21.358079Z",
     "iopub.status.idle": "2024-11-24T12:32:21.363279Z",
     "shell.execute_reply": "2024-11-24T12:32:21.362694Z"
    },
    "papermill": {
     "duration": 0.01281,
     "end_time": "2024-11-24T12:32:21.364838",
     "exception": false,
     "start_time": "2024-11-24T12:32:21.352028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# auxiliary function to read JSON files\n",
    "def read_json_info(jsonFilePath: str) -> dict:\n",
    "    if os.path.exists(jsonFilePath):\n",
    "        with open(jsonFilePath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da77c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:21.376550Z",
     "iopub.status.busy": "2024-11-24T12:32:21.376308Z",
     "iopub.status.idle": "2024-11-24T12:32:21.381471Z",
     "shell.execute_reply": "2024-11-24T12:32:21.380844Z"
    },
    "papermill": {
     "duration": 0.012634,
     "end_time": "2024-11-24T12:32:21.382923",
     "exception": false,
     "start_time": "2024-11-24T12:32:21.370289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# auxiliary Python decorator to execute a function again, if its execution fails\n",
    "# this is helpful when calling the Gemini's API since Gemini has a rate limiter and, if an execution fails for that, there will be some waiting time before retrying\n",
    "import time\n",
    "\n",
    "def retry_on_failure(wait_time_seconds=60, max_retries=5):\n",
    "    def decorator_retry(func):\n",
    "        \n",
    "        def wrapper_retry(*args, **kwargs):\n",
    "            retries = 0\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    retries += 1\n",
    "                    if retries < max_retries:\n",
    "                        print(\n",
    "                            f\"Function failed with error: {e}. Retrying in {wait_time_seconds} seconds... (Attempt {retries}/{max_retries})\"\n",
    "                        )\n",
    "                        time.sleep(wait_time_seconds)\n",
    "                    else:\n",
    "                        print(f\"Function failed after {max_retries} attempts.\")\n",
    "                        raise e\n",
    "        return wrapper_retry\n",
    "\n",
    "    return decorator_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2af126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:21.394404Z",
     "iopub.status.busy": "2024-11-24T12:32:21.394189Z",
     "iopub.status.idle": "2024-11-24T12:32:21.397723Z",
     "shell.execute_reply": "2024-11-24T12:32:21.396934Z"
    },
    "papermill": {
     "duration": 0.011177,
     "end_time": "2024-11-24T12:32:21.399384",
     "exception": false,
     "start_time": "2024-11-24T12:32:21.388207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/input/tenders-and-companies-websites'\n",
    "working_path = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a6f673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:21.411436Z",
     "iopub.status.busy": "2024-11-24T12:32:21.411196Z",
     "iopub.status.idle": "2024-11-24T12:32:23.386409Z",
     "shell.execute_reply": "2024-11-24T12:32:23.385461Z"
    },
    "papermill": {
     "duration": 1.983503,
     "end_time": "2024-11-24T12:32:23.388448",
     "exception": false,
     "start_time": "2024-11-24T12:32:21.404945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/tenders\n",
    "tenders_working_path = os.path.join(working_path, 'tenders')\n",
    "\n",
    "!mkdir -p /kaggle/working/companies\n",
    "companies_working_path = os.path.join(working_path, 'companies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b049241",
   "metadata": {
    "papermill": {
     "duration": 0.005207,
     "end_time": "2024-11-24T12:32:23.399456",
     "exception": false,
     "start_time": "2024-11-24T12:32:23.394249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fetch information about companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994765ce",
   "metadata": {
    "papermill": {
     "duration": 0.005093,
     "end_time": "2024-11-24T12:32:23.409859",
     "exception": false,
     "start_time": "2024-11-24T12:32:23.404766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Overview\n",
    "Information about interesting companies is obtained from their websites.\n",
    "\n",
    "To generate data out of the companies' websites, we implemented a crawler.\n",
    "The final output of the crawler is a JSON file, in which each field refers to a company: for each company, all the information of the websites is merged.\n",
    "\n",
    "> To make things easier, the mentioned JSON file will be fetched from a Git repository where the crawling function has already been executed.\n",
    "\n",
    "## Details about the crawling process:\n",
    "- **Recursive scan**: after a webpage is scanned and its content is stored, eventual found sublinks are scanned, as well. A limit of the wepages to download is given as input.\n",
    "- **Redundant information is deleted**: if some website content can be found multiple times in all the webpages of one company, then it is skipped. *Example*: undesired and redundant lines like \"Contact Us\" are removed, ensuring that the final content does not include unnecessary sentences.\n",
    "- **Caching of already downloaded pages**: for each webpage, the content is stored in a JSON file, as well as the found sublinks. *Example*: after a run with a limit of N pages, other runs with less than N pages will use the stored files instead downloading data from internet; at the contrary, if the limit is increased to M > N pages, only M - N additional pages will be downloaded while the first N pages will be taken from the stored file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f198768",
   "metadata": {
    "papermill": {
     "duration": 0.005252,
     "end_time": "2024-11-24T12:32:23.420489",
     "exception": false,
     "start_time": "2024-11-24T12:32:23.415237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the companies' info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd201f",
   "metadata": {
    "papermill": {
     "duration": 0.005283,
     "end_time": "2024-11-24T12:32:23.431032",
     "exception": false,
     "start_time": "2024-11-24T12:32:23.425749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chat with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b923b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:23.443250Z",
     "iopub.status.busy": "2024-11-24T12:32:23.442928Z",
     "iopub.status.idle": "2024-11-24T12:32:25.045293Z",
     "shell.execute_reply": "2024-11-24T12:32:25.044451Z"
    },
    "papermill": {
     "duration": 1.610851,
     "end_time": "2024-11-24T12:32:25.047265",
     "exception": false,
     "start_time": "2024-11-24T12:32:23.436414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_info.input_token_limit=1000000\n",
      "model_info.output_token_limit=8192\n"
     ]
    }
   ],
   "source": [
    "# API key got here: https://ai.google.dev/tutorials/setup\n",
    "\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "\n",
    "genai.configure(api_key = secret_key)\n",
    "\n",
    "model_name = 'gemini-1.5-flash-latest'\n",
    "model = genai.GenerativeModel(model_name=model_name)\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "model_info = genai.get_model(f\"models/{model_name}\")\n",
    "print(f\"{model_info.input_token_limit=}\")\n",
    "print(f\"{model_info.output_token_limit=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8300ff1",
   "metadata": {
    "papermill": {
     "duration": 0.005322,
     "end_time": "2024-11-24T12:32:25.058608",
     "exception": false,
     "start_time": "2024-11-24T12:32:25.053286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyze the tenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8afb8e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:25.071286Z",
     "iopub.status.busy": "2024-11-24T12:32:25.070711Z",
     "iopub.status.idle": "2024-11-24T12:32:25.085104Z",
     "shell.execute_reply": "2024-11-24T12:32:25.084518Z"
    },
    "papermill": {
     "duration": 0.022624,
     "end_time": "2024-11-24T12:32:25.086684",
     "exception": false,
     "start_time": "2024-11-24T12:32:25.064060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the json file related to tenders from the input dataset\n",
    "tenders_info_json_path = os.path.join(dataset_path, 'tenders_info.json')\n",
    "tenders_info = read_json_info(tenders_info_json_path)\n",
    "\n",
    "# tenders_info is a dictionary, where the key is the name of the tender file and the related value its information\n",
    "# print(tenders_info[\"tender_wind.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2bf58e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:25.098436Z",
     "iopub.status.busy": "2024-11-24T12:32:25.098182Z",
     "iopub.status.idle": "2024-11-24T12:32:25.101530Z",
     "shell.execute_reply": "2024-11-24T12:32:25.100822Z"
    },
    "papermill": {
     "duration": 0.011083,
     "end_time": "2024-11-24T12:32:25.103193",
     "exception": false,
     "start_time": "2024-11-24T12:32:25.092110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list the processed tender files\n",
    "tenders = tenders_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04855f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:25.114953Z",
     "iopub.status.busy": "2024-11-24T12:32:25.114695Z",
     "iopub.status.idle": "2024-11-24T12:32:25.119056Z",
     "shell.execute_reply": "2024-11-24T12:32:25.118412Z"
    },
    "papermill": {
     "duration": 0.011938,
     "end_time": "2024-11-24T12:32:25.120521",
     "exception": false,
     "start_time": "2024-11-24T12:32:25.108583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tender_prompt_template_technical = \"\"\"\n",
    "You are an experienced technical tender engineer. \n",
    "The document you have is a tender, that contains also technical requirements for a project.\n",
    "Think step by step on how to look for the relevant technical requirements and make a detailed summary.\n",
    "The content of the document is: \"\"\"\n",
    "tender_prompts_technical = []\n",
    "for info in tenders_info.values():\n",
    "    tender_prompts_technical.append(f\"You have a document called {info['name']} . \" + tender_prompt_template_technical + f\"{info['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca8cb32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:25.132336Z",
     "iopub.status.busy": "2024-11-24T12:32:25.132086Z",
     "iopub.status.idle": "2024-11-24T12:32:25.136198Z",
     "shell.execute_reply": "2024-11-24T12:32:25.135413Z"
    },
    "papermill": {
     "duration": 0.011844,
     "end_time": "2024-11-24T12:32:25.137779",
     "exception": false,
     "start_time": "2024-11-24T12:32:25.125935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tender_prompt_template_commercial = \"\"\"\n",
    "You are an experienced commercial tender manager. \n",
    "The document you have is a tender, that contains also commercial requirements for a project.\n",
    "Think step by step on how to look for the relevant commercial requirements and make a detailed summary.\n",
    "The content of the document is: \"\n",
    "\"\"\"\n",
    "tender_prompts_commercial = []\n",
    "for info in tenders_info.values():\n",
    "    tender_prompts_commercial.append(f\"You have a document called {info['name']} . \" + tender_prompt_template_commercial + f\"{info['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2f63ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:32:25.149775Z",
     "iopub.status.busy": "2024-11-24T12:32:25.149475Z",
     "iopub.status.idle": "2024-11-24T12:33:11.152285Z",
     "shell.execute_reply": "2024-11-24T12:33:11.151276Z"
    },
    "papermill": {
     "duration": 46.010854,
     "end_time": "2024-11-24T12:33:11.154217",
     "exception": false,
     "start_time": "2024-11-24T12:32:25.143363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tender_technical: Generating response for tender tender_wind.pdf ...\n",
      "tender_technical: Response for tender tender_wind.pdf generated.\n",
      "tender_technical: Generating response for tender tender_solar.pdf ...\n",
      "tender_technical: Response for tender tender_solar.pdf generated.\n",
      "tender_technical: Responses stored into /kaggle/working/tenders/tenders_technical.json\n",
      "tender_technical: Analysis concluded!\n",
      "\n",
      "tender_commercial: Generating response for tender tender_wind.pdf ...\n",
      "tender_commercial: Response for tender tender_wind.pdf generated.\n",
      "tender_commercial: Generating response for tender tender_solar.pdf ...\n",
      "tender_commercial: Response for tender tender_solar.pdf generated.\n",
      "tender_commercial: Responses stored into /kaggle/working/tenders/tenders_commercial.json\n",
      "tender_commercial: Analysis concluded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@retry_on_failure(wait_time_seconds=60)\n",
    "def get_responses_tenders(subject, tender_prompts):\n",
    "    tenders_json_file_path = os.path.join(tenders_working_path, f'tenders_{subject}.json')\n",
    "    \n",
    "    if os.path.exists(tenders_json_file_path):\n",
    "        responses = read_json_info(tenders_json_file_path)\n",
    "        print(f\"tender_{subject}: Responses loaded from file {tenders_json_file_path}\")\n",
    "    else:\n",
    "        for tender_prompt, tender_name in zip(tender_prompts, tenders):\n",
    "            print(f\"tender_{subject}: Generating response for tender {tender_name} ...\")\n",
    "            response = chat.send_message(tender_prompt)\n",
    "            # print(response.text)\n",
    "\n",
    "            responses = {}\n",
    "            responses[tender_name] = {'prompt': tender_prompt, 'answer': response.text}\n",
    "            print(f\"tender_{subject}: Response for tender {tender_name} generated.\")\n",
    "    \n",
    "        with open(tenders_json_file_path, 'w') as f:\n",
    "            json.dump(responses, f, ensure_ascii=True, indent=4)\n",
    "        print(f\"tender_{subject}: Responses stored into {tenders_json_file_path}\")\n",
    "    \n",
    "    print(f\"tender_{subject}: Analysis concluded!\\n\")\n",
    "    return responses\n",
    "\n",
    "# each call of get_responses_tenders() will generate a tenders_{subject}.json file\n",
    "# each generated file so will contain the Gemnini's responses for a given subject\n",
    "response_technical = get_responses_tenders(\"technical\", tender_prompts_technical)\n",
    "response_commercial = get_responses_tenders(\"commercial\", tender_prompts_commercial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212771e",
   "metadata": {
    "papermill": {
     "duration": 0.00546,
     "end_time": "2024-11-24T12:33:11.165648",
     "exception": false,
     "start_time": "2024-11-24T12:33:11.160188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyze the companies products and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d8953c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:33:11.178372Z",
     "iopub.status.busy": "2024-11-24T12:33:11.177845Z",
     "iopub.status.idle": "2024-11-24T12:33:11.292132Z",
     "shell.execute_reply": "2024-11-24T12:33:11.291191Z"
    },
    "papermill": {
     "duration": 0.123063,
     "end_time": "2024-11-24T12:33:11.294412",
     "exception": false,
     "start_time": "2024-11-24T12:33:11.171349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "companies_json_path = os.path.join(dataset_path, 'companies_info.json')\n",
    "companies_info = read_json_info(companies_json_path)\n",
    "\n",
    "# companies_info is a dictionary, where the key is the name of the company and the related value its information\n",
    "# print(companies_info[\"SIEMENS\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5ad8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:33:11.307310Z",
     "iopub.status.busy": "2024-11-24T12:33:11.307024Z",
     "iopub.status.idle": "2024-11-24T12:35:08.731384Z",
     "shell.execute_reply": "2024-11-24T12:35:08.730474Z"
    },
    "papermill": {
     "duration": 117.443708,
     "end_time": "2024-11-24T12:35:08.744117",
     "exception": false,
     "start_time": "2024-11-24T12:33:11.300409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies_HITACHI: Generating response for company HITACHI ...\n",
      "companies_HITACHI: Responses stored into /kaggle/working/companies/companies_HITACHI.json\n",
      "companies_HITACHI: Response for company HITACHI generated!\n",
      "companies_SIEMENS: Generating response for company SIEMENS ...\n",
      "Function failed with error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 60 seconds... (Attempt 1/5)\n",
      "companies_SIEMENS: Generating response for company SIEMENS ...\n",
      "companies_SIEMENS: Responses stored into /kaggle/working/companies/companies_SIEMENS.json\n",
      "companies_SIEMENS: Response for company SIEMENS generated!\n"
     ]
    }
   ],
   "source": [
    "@retry_on_failure(wait_time_seconds=60)\n",
    "def get_response_companies(company_name):\n",
    "    companies_json_file_path = os.path.join(companies_working_path, f'companies_{company_name}.json')\n",
    "    \n",
    "    if os.path.exists(companies_json_file_path):\n",
    "        responses = read_json_info(companies_json_file_path)\n",
    "        print(f\"companies_{company_name}: Responses loaded from file {companies_json_file_path}\")\n",
    "    else:\n",
    "        print(f\"companies_{company_name}: Generating response for company {company_name} ...\")\n",
    "        responses = {}\n",
    "        company_prompt = f\"These are the information of products and solutions for the company {company_name} : {companies_info[company_name]}\"\n",
    "        response = chat.send_message(company_prompt)\n",
    "        responses[company_name] = {'prompt': company_prompt, 'answer': response.text}\n",
    "\n",
    "        with open(companies_json_file_path, 'w') as f:\n",
    "                json.dump(responses, f, ensure_ascii=True, indent=4)\n",
    "        print(f\"companies_{company_name}: Responses stored into {companies_json_file_path}\")\n",
    "\n",
    "    print(f\"companies_{company_name}: Response for company {company_name} generated!\")\n",
    "    return responses\n",
    "\n",
    "# each call of get_responses_companies() will generate a companies_{company_name}.json file\n",
    "# each generated file so will contain the Gemnini's responses for a given company\n",
    "# the purpose of generating responses given companies information is to store it in the chat history\n",
    "response_hitachi = get_response_companies(\"HITACHI\")\n",
    "response_siemens = get_response_companies(\"SIEMENS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740bb74",
   "metadata": {
    "papermill": {
     "duration": 0.010378,
     "end_time": "2024-11-24T12:35:08.765078",
     "exception": false,
     "start_time": "2024-11-24T12:35:08.754700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build a chat history based on previous prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ad0456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:35:08.784420Z",
     "iopub.status.busy": "2024-11-24T12:35:08.783501Z",
     "iopub.status.idle": "2024-11-24T12:35:08.801749Z",
     "shell.execute_reply": "2024-11-24T12:35:08.800681Z"
    },
    "papermill": {
     "duration": 0.02781,
     "end_time": "2024-11-24T12:35:08.803449",
     "exception": false,
     "start_time": "2024-11-24T12:35:08.775639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example how to include the chat history here https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_chat.ipynb\n",
    "# description of the Content class here https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai/GenerativeModel.md\n",
    "from google.generativeai.protos import Content, Part\n",
    "\n",
    "history_chat = []\n",
    "\n",
    "def add_history_to_chat_single(response, user, history_chat):\n",
    "    query = Part()\n",
    "    query.text = f\"{user}: {response['prompt']}\"\n",
    "    history_chat.append(Content(role=\"user\", parts=[query]))\n",
    "\n",
    "    answer = Part()\n",
    "    answer.text = response['answer']\n",
    "    history_chat.append(Content(role=\"model\", parts=[answer]))\n",
    "    return\n",
    "\n",
    "def add_history_to_chat(responses, user, history_chat):\n",
    "    for response in responses.values():\n",
    "        add_history_to_chat_single(response, user, history_chat)\n",
    "    return \n",
    "\n",
    "add_history_to_chat(response_technical, \"technical engineer\", history_chat)\n",
    "add_history_to_chat(response_commercial, \"commercial manager\", history_chat)\n",
    "add_history_to_chat(response_siemens, \"sales manager for siemens\", history_chat)\n",
    "add_history_to_chat(response_hitachi, \"sales manager for hitachi\", history_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ade4a8",
   "metadata": {
    "papermill": {
     "duration": 0.005836,
     "end_time": "2024-11-24T12:35:08.815539",
     "exception": false,
     "start_time": "2024-11-24T12:35:08.809703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc239e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:35:08.835726Z",
     "iopub.status.busy": "2024-11-24T12:35:08.835388Z",
     "iopub.status.idle": "2024-11-24T12:35:08.840403Z",
     "shell.execute_reply": "2024-11-24T12:35:08.839582Z"
    },
    "papermill": {
     "duration": 0.017538,
     "end_time": "2024-11-24T12:35:08.842418",
     "exception": false,
     "start_time": "2024-11-24T12:35:08.824880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the decorator ensures that, if an error occurs, the function will be executed again\n",
    "@retry_on_failure(wait_time_seconds=60, max_retries=3)\n",
    "def ask_gemini_with_history(prompt, chat_with_memory=None, model=None, history=[]):\n",
    "    \"\"\"\n",
    "    function to call Gemini, providing chat history\n",
    "    if a chat is already available, it will be used\n",
    "    \"\"\"\n",
    "    if chat_with_memory == None:\n",
    "        # since no chat is already available, create a new one\n",
    "        chat_with_memory = model.start_chat(history=history)\n",
    "    \n",
    "    response = chat_with_memory.send_message(prompt)\n",
    "    return response, chat_with_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa889245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:35:08.861545Z",
     "iopub.status.busy": "2024-11-24T12:35:08.860873Z",
     "iopub.status.idle": "2024-11-24T12:35:38.542244Z",
     "shell.execute_reply": "2024-11-24T12:35:38.541340Z"
    },
    "papermill": {
     "duration": 29.690947,
     "end_time": "2024-11-24T12:35:38.543976",
     "exception": false,
     "start_time": "2024-11-24T12:35:08.853029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The prompt assigns three distinct roles:\n",
       "\n",
       "1. **Technical Tender Engineer:** This role focuses on the technical aspects of a tender document, specifically identifying and summarizing the technical requirements of a project.\n",
       "\n",
       "2. **Commercial Tender Manager:** This role centers on the commercial aspects of a tender, identifying and summarizing the financial and contractual requirements.\n",
       "\n",
       "3. **Sales Manager (for Siemens/Hitachi):** This is a company-specific role focused on understanding the company's product portfolio and how it aligns with the needs outlined in a tender document.  The prompt requests analysis of each company's offerings, not specific roles *within* the company.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_roles = \"Which are the roles given in the prompt from the user? There are only two for tenders and one for company\"\n",
    "response_roles, gemini_chat = ask_gemini_with_history(prompt=prompt_roles, model=model, history=history_chat)\n",
    "\n",
    "Markdown(response_roles.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f3f5dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:35:38.557563Z",
     "iopub.status.busy": "2024-11-24T12:35:38.557317Z",
     "iopub.status.idle": "2024-11-24T12:35:38.561541Z",
     "shell.execute_reply": "2024-11-24T12:35:38.560737Z"
    },
    "papermill": {
     "duration": 0.012915,
     "end_time": "2024-11-24T12:35:38.563248",
     "exception": false,
     "start_time": "2024-11-24T12:35:38.550333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the last response to the chat history\n",
    "add_history_to_chat_single({'prompt': prompt_roles, 'answer': response_roles.text}, \"technical engineer\", history_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271caf80",
   "metadata": {
    "papermill": {
     "duration": 0.006048,
     "end_time": "2024-11-24T12:35:38.576257",
     "exception": false,
     "start_time": "2024-11-24T12:35:38.570209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Find the most suitable company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf9a0ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:35:38.589141Z",
     "iopub.status.busy": "2024-11-24T12:35:38.588877Z",
     "iopub.status.idle": "2024-11-24T12:35:38.592598Z",
     "shell.execute_reply": "2024-11-24T12:35:38.591806Z"
    },
    "papermill": {
     "duration": 0.012154,
     "end_time": "2024-11-24T12:35:38.594300",
     "exception": false,
     "start_time": "2024-11-24T12:35:38.582146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_match = \"\"\"\n",
    "\n",
    "1. For company SIEMENS and HITACHI, find the respective relevant products and solutions with respect to the analyzed tenders.\n",
    "   The information is in the form of text I provided, then you do not need to read additional documents or access to websites.\n",
    "   \n",
    "   \n",
    "2. Calculate an affinity score in percentage for each company based on analysis in point 1. Explain the way how you computed this percentage.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "075627b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:35:38.607159Z",
     "iopub.status.busy": "2024-11-24T12:35:38.606887Z",
     "iopub.status.idle": "2024-11-24T12:38:39.484612Z",
     "shell.execute_reply": "2024-11-24T12:38:39.483712Z"
    },
    "papermill": {
     "duration": 180.893071,
     "end_time": "2024-11-24T12:38:39.493288",
     "exception": false,
     "start_time": "2024-11-24T12:35:38.600217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the most suitable company for the tenders ...\n",
      "Function failed with error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 60 seconds... (Attempt 1/3)\n",
      "Response to the prompts is ready!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To perform this analysis, I need the tender specifications.  The previous responses analyzed the Siemens and Hitachi product information but lacked the crucial information: the detailed requirements of the Barclayville Solar Power Plant tender.  Please provide the complete tender specifications so I can match them against the companies' offerings and calculate affinity scores.\n",
       "\n",
       "\n",
       "Once you provide the tender specifications, my analysis will proceed in these steps:\n",
       "\n",
       "**Step 1: Identifying Relevant Products and Solutions**\n",
       "\n",
       "I will compare each item in the tender document against the Siemens and Hitachi product descriptions.  For each tender item, I will note which products or solutions from each company are relevant.  This will require a detailed comparison and might include multiple products from one company to satisfy a single tender item.\n",
       "\n",
       "**Step 2: Calculating Affinity Scores**\n",
       "\n",
       "The affinity score will be a percentage representing the degree to which each company's offerings match the tender's requirements.  I will calculate this in a weighted fashion:\n",
       "\n",
       "* **Weighting of Tender Items:**  First, I will assign weights to each item in the tender based on its relative importance (as implied by the tender document or through additional information you can provide).  For instance, the solar array might be weighted higher than the spare parts. The more important the tender item, the higher the weight.  The sum of all weights should equal 1 (or 100%).\n",
       "\n",
       "* **Match Score for Each Item:** For each tender item, I will assign a match score (0-1 or 0-100%) to each company's relevant offering.  A score of 1 (or 100%) indicates a perfect match; 0 (or 0%) means no match. Partial matches will receive intermediate scores.  The match score reflects both the technical and commercial suitability of the offering.\n",
       "\n",
       "* **Weighted Affinity Score:**  The weighted affinity score for each company will be calculated as the sum of (Weight of Tender Item * Match Score for that item) across all tender items. This will be expressed as a percentage.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "Let's say the tender has three items: Solar Array (Weight 0.5), Inverter (Weight 0.3), and Monitoring System (Weight 0.2).\n",
       "\n",
       "| Company | Solar Array Match | Inverter Match | Monitoring System Match | Weighted Affinity Score |\n",
       "|---|---|---|---|---|\n",
       "| Siemens | 0.9 (90%) | 0.8 (80%) | 1.0 (100%) | (0.5 * 0.9) + (0.3 * 0.8) + (0.2 * 1.0) = 0.83 or 83% |\n",
       "| Hitachi | 0.7 (70%) | 0.9 (90%) | 0.7 (70%) | (0.5 * 0.7) + (0.3 * 0.9) + (0.2 * 0.7) = 0.7 or 70% |\n",
       "\n",
       "\n",
       "This example shows a higher affinity score for Siemens. The final scores will depend heavily on the specific tender requirements and the weighting assigned to each item.  Provide the tender details for a complete analysis.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Finding the most suitable company for the tenders ...\")\n",
    "response_match, gemini_chat = ask_gemini_with_history(prompt=prompt_match, chat_with_memory=gemini_chat)\n",
    "print(\"Response to the prompts is ready!\")\n",
    "\n",
    "Markdown(response_match.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e269440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:38:39.507083Z",
     "iopub.status.busy": "2024-11-24T12:38:39.506803Z",
     "iopub.status.idle": "2024-11-24T12:38:39.511239Z",
     "shell.execute_reply": "2024-11-24T12:38:39.510177Z"
    },
    "papermill": {
     "duration": 0.0132,
     "end_time": "2024-11-24T12:38:39.512807",
     "exception": false,
     "start_time": "2024-11-24T12:38:39.499607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the last response to the chat history\n",
    "add_history_to_chat_single({'prompt': prompt_match, 'answer': response_match.text}, \"technical engineer\", history_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ffe2a",
   "metadata": {
    "papermill": {
     "duration": 0.006078,
     "end_time": "2024-11-24T12:38:39.525150",
     "exception": false,
     "start_time": "2024-11-24T12:38:39.519072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate the clause-by-clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218672cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:38:39.538933Z",
     "iopub.status.busy": "2024-11-24T12:38:39.538683Z",
     "iopub.status.idle": "2024-11-24T12:38:39.542383Z",
     "shell.execute_reply": "2024-11-24T12:38:39.541579Z"
    },
    "papermill": {
     "duration": 0.012235,
     "end_time": "2024-11-24T12:38:39.543944",
     "exception": false,
     "start_time": "2024-11-24T12:38:39.531709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "\n",
    "Consider the company with the highest affinity score \n",
    "and return the clause by clause analysis considering technical and commercial compliant and not-compliant requirements\n",
    "of the tender with respect to the selected company. Report also the URL of the source where you found the informations.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bec5e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:38:39.557426Z",
     "iopub.status.busy": "2024-11-24T12:38:39.557210Z",
     "iopub.status.idle": "2024-11-24T12:38:39.560562Z",
     "shell.execute_reply": "2024-11-24T12:38:39.559831Z"
    },
    "papermill": {
     "duration": 0.011831,
     "end_time": "2024-11-24T12:38:39.562188",
     "exception": false,
     "start_time": "2024-11-24T12:38:39.550357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an experienced team of business development managers and tender engineers, commercial managers.\n",
    "You need to create a detailed clause by clause from the tender documentations and the most affine company specifications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3eaffea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:38:39.575904Z",
     "iopub.status.busy": "2024-11-24T12:38:39.575422Z",
     "iopub.status.idle": "2024-11-24T12:40:11.335089Z",
     "shell.execute_reply": "2024-11-24T12:40:11.334204Z"
    },
    "papermill": {
     "duration": 91.774821,
     "end_time": "2024-11-24T12:40:11.343370",
     "exception": false,
     "start_time": "2024-11-24T12:38:39.568549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the clause by clause ...\n",
      "Function failed with error: 429 Resource has been exhausted (e.g. check quota).. Retrying in 60 seconds... (Attempt 1/3)\n",
      "Response to the prompts is ready!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I cannot provide a clause-by-clause analysis of a tender document and company specifications without the actual tender document and the relevant company specifications. My previous responses emphasized that I need this information to proceed.\n",
       "\n",
       "To create the requested analysis, please provide:\n",
       "\n",
       "1. **The complete tender document for the Barclayville Solar Power Plant:** This should include all clauses, technical specifications, and commercial requirements.\n",
       "\n",
       "2. **The company specifications (relevant product descriptions and capabilities):**  This should be the detailed technical and commercial information for the company with the highest affinity score (as determined by the analysis in the previous response, once you provide the tender). Ideally, you will provide links to the relevant source documents to verify accuracy, as I cannot access external websites.\n",
       "\n",
       "Once you provide these documents, I can conduct a detailed, clause-by-clause analysis comparing the tender requirements with the selected company's capabilities. The analysis will indicate which clauses are met, which are not, and the reasons for compliance or non-compliance (both technically and commercially). This will involve:\n",
       "\n",
       "* **Careful Review:**  Reading each clause in the tender document to understand the requirements.\n",
       "\n",
       "* **Matching to Company Specifications:**  Identifying the corresponding company specifications or capabilities that would satisfy each clause.\n",
       "\n",
       "* **Compliance Assessment:**  Determining whether the company’s offerings meet each clause's technical and commercial requirements. This will necessitate precise, detailed comparison of specifications.\n",
       "\n",
       "* **Non-Compliance Reasons:**  Explaining why a clause is not met (e.g., missing features, different specifications, cost implications).\n",
       "\n",
       "* **Structured Reporting:**  Presenting the analysis in a clear, well-organized format (likely a table), with each clause addressed and the relevant company information and compliance status provided.  Each line item will include the URL of the source document.\n",
       "\n",
       "\n",
       "Without the required documents, I cannot perform the requested clause-by-clause analysis.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generating the clause by clause ...\")\n",
    "prompt_clause_by_clause = f\"{system_prompt} {user_prompt}\"\n",
    "response_clause_by_clause, gemini_chat = ask_gemini_with_history(prompt=prompt_clause_by_clause, chat_with_memory=gemini_chat)\n",
    "print(\"Response to the prompts is ready!\")\n",
    "\n",
    "Markdown(response_clause_by_clause.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "774967c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:40:11.357759Z",
     "iopub.status.busy": "2024-11-24T12:40:11.357460Z",
     "iopub.status.idle": "2024-11-24T12:40:11.361713Z",
     "shell.execute_reply": "2024-11-24T12:40:11.361007Z"
    },
    "papermill": {
     "duration": 0.013364,
     "end_time": "2024-11-24T12:40:11.363301",
     "exception": false,
     "start_time": "2024-11-24T12:40:11.349937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the last response to the chat history\n",
    "add_history_to_chat_single({'prompt': prompt_clause_by_clause, 'answer': response_clause_by_clause.text}, \"technical engineer\", history_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa059707",
   "metadata": {
    "papermill": {
     "duration": 0.006372,
     "end_time": "2024-11-24T12:40:11.376386",
     "exception": false,
     "start_time": "2024-11-24T12:40:11.370014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Count the overall tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcbf6dd",
   "metadata": {
    "papermill": {
     "duration": 0.006184,
     "end_time": "2024-11-24T12:40:11.389143",
     "exception": false,
     "start_time": "2024-11-24T12:40:11.382959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The total number of token can be computed by counting the tokens of history_chat, since the new responses have been appended to it for each call of Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09490c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:40:11.403126Z",
     "iopub.status.busy": "2024-11-24T12:40:11.402879Z",
     "iopub.status.idle": "2024-11-24T12:40:17.321968Z",
     "shell.execute_reply": "2024-11-24T12:40:17.320966Z"
    },
    "papermill": {
     "duration": 5.928286,
     "end_time": "2024-11-24T12:40:17.323846",
     "exception": false,
     "start_time": "2024-11-24T12:40:11.395560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.count_tokens(history_chat)=total_tokens: 664426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model.count_tokens(history_chat)=}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6154170,
     "sourceId": 9998649,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 478.984115,
   "end_time": "2024-11-24T12:40:17.749000",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-24T12:32:18.764885",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
