{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tender2Project\nThe following Kaggle notebook exploits the long context window of Gemini, in order to fulfill the following targets:\n- Analyze the tender for a project.\n- Analyze the information about possible products, provided from different companies.\n- Find the best combination of products to build the project in the tender, identifying the most compliant company as well.\n\n## Notebook structure\nThe notebook is composed by different parts, each one with a specific target:\n- A tender for a project is parsed, such that its information is converted to text.\n- Information scraped from the websites of different companies is loaded as text.\n- All the text is forwarded to Gemini, whereas a system prompt and a user prompt are written to explain the purposed o Gemini.\n\n## Theoretical aspects\nThe current way to use Gemini makes use of the following properties of a LLM (Large Language Model) like Gemini:\n|  **LLM property** | **Where it is used** | **How it is used** |\n|:-----------------:|:--------------------:|:------------------:|\n|     Reasoning     |          TBD         |         TBD        |\n|       Memory      |          TBD         |         TBD        |\n| Chain of Thoughts |          TBD         |         TBD        |\n|                   |                      |                    |","metadata":{}},{"cell_type":"markdown","source":"Clean the working directory","metadata":{}},{"cell_type":"code","source":"! rm -r /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:06.168493Z","iopub.execute_input":"2024-11-22T23:13:06.169413Z","iopub.status.idle":"2024-11-22T23:13:07.168118Z","shell.execute_reply.started":"2024-11-22T23:13:06.169375Z","shell.execute_reply":"2024-11-22T23:13:07.166991Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"from IPython.display import Markdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:07.170742Z","iopub.execute_input":"2024-11-22T23:13:07.171496Z","iopub.status.idle":"2024-11-22T23:13:07.175753Z","shell.execute_reply.started":"2024-11-22T23:13:07.171450Z","shell.execute_reply":"2024-11-22T23:13:07.174829Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"# Analyze the tenders","metadata":{}},{"cell_type":"markdown","source":"Locate the tenders - in PDF format.","metadata":{}},{"cell_type":"code","source":"# fetch the script to download content from GitHub\n!wget https://raw.githubusercontent.com/gabripo/kaggle-gemini-long-context/refs/heads/main/github_downloader.py -P /kaggle/working/scripts\n\n# add downloaded script to the Python path\nimport sys\nsys.path.append('/kaggle/working/scripts')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:07.176657Z","iopub.execute_input":"2024-11-22T23:13:07.176928Z","iopub.status.idle":"2024-11-22T23:13:08.448401Z","shell.execute_reply.started":"2024-11-22T23:13:07.176903Z","shell.execute_reply":"2024-11-22T23:13:08.447514Z"}},"outputs":[{"name":"stdout","text":"--2024-11-22 23:13:08--  https://raw.githubusercontent.com/gabripo/kaggle-gemini-long-context/refs/heads/main/github_downloader.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1722 (1.7K) [text/plain]\nSaving to: '/kaggle/working/scripts/github_downloader.py'\n\ngithub_downloader.p 100%[===================>]   1.68K  --.-KB/s    in 0s      \n\n2024-11-22 23:13:08 (28.6 MB/s) - '/kaggle/working/scripts/github_downloader.py' saved [1722/1722]\n\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"import github_downloader\n\ngithub_downloader.download_files_from_github_repo(folderName=\"tenders\", saveFolder=\"/kaggle/working/tenders\", extension=\"pdf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:08.449859Z","iopub.execute_input":"2024-11-22T23:13:08.450153Z","iopub.status.idle":"2024-11-22T23:13:09.270087Z","shell.execute_reply.started":"2024-11-22T23:13:08.450120Z","shell.execute_reply":"2024-11-22T23:13:09.269114Z"}},"outputs":[{"name":"stdout","text":"Downloading tender_solar.pdf...\n/kaggle/working/tenders/tender_solar.pdf downloaded successfully.\nDownloading tender_wind.pdf...\n/kaggle/working/tenders/tender_wind.pdf downloaded successfully.\nAll files downloaded.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"import os\n\n# if the PDF file is given as Kaggle Input (for example, manually uploaded), change the use_kaggle_input to True\nuse_kaggle_input_tender = False if os.path.exists('/kaggle/working/tenders') else True\nif use_kaggle_input_tender:\n    tenders_file_path = '/kaggle/input/tenders'\nelse:\n    tenders_file_path = '/kaggle/working/tenders'\n\nprint(f\"The folder {tenders_file_path} will be considered as containing the tenders\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:09.272221Z","iopub.execute_input":"2024-11-22T23:13:09.272496Z","iopub.status.idle":"2024-11-22T23:13:09.277644Z","shell.execute_reply.started":"2024-11-22T23:13:09.272469Z","shell.execute_reply":"2024-11-22T23:13:09.276814Z"}},"outputs":[{"name":"stdout","text":"The folder /kaggle/working/tenders will be considered as containing the tenders\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"Installing required Python packages to analyze the tender - in PDF format.","metadata":{}},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:09.278538Z","iopub.execute_input":"2024-11-22T23:13:09.278799Z","iopub.status.idle":"2024-11-22T23:13:17.430621Z","shell.execute_reply.started":"2024-11-22T23:13:09.278763Z","shell.execute_reply":"2024-11-22T23:13:17.429738Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"Extract information from the tenders.\nThe output will be a text.","metadata":{}},{"cell_type":"code","source":"import os\nfrom PyPDF2 import PdfReader\n\ntenders = [t for t in os.listdir(tenders_file_path) if t.endswith(\".pdf\")]\ntenders_info = {}\nfor tender in tenders:\n    print(f\"Reading the tender {tender} ...\")\n    reader = PdfReader(os.path.join(tenders_file_path, tender))\n\n    tenders_info[tender] = {}\n    tenders_info[tender][\"name\"] = tender\n    tenders_info[tender][\"content\"] = \"\\n\".join([page.extract_text() for page in reader.pages])\n\n# information for each tender can be accessed by:\n# tenders_info[tenders[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:17.432406Z","iopub.execute_input":"2024-11-22T23:13:17.433225Z","iopub.status.idle":"2024-11-22T23:13:18.904519Z","shell.execute_reply.started":"2024-11-22T23:13:17.433177Z","shell.execute_reply":"2024-11-22T23:13:18.903502Z"}},"outputs":[{"name":"stdout","text":"Reading the tender tender_solar.pdf ...\nReading the tender tender_wind.pdf ...\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"# Fetch information about companies","metadata":{}},{"cell_type":"markdown","source":"## Overview\nInformation about interesting companies is obtained from their websites.\n\nTo generate data out of the companies' websites, we implemented a crawler.\nThe final output of the crawler is a JSON file, in which each field refers to a company: for each company, all the information of the websites is merged.\n\n> To make things easier, the mentioned JSON file will be fetched from a Git repository where the crawling function has already been executed.\n\n## Details about the crawling process:\n- **Recursive scan**: after a webpage is scanned and its content is stored, eventual found sublinks are scanned, as well. A limit of the wepages to download is given as input.\n- **Redundant information is deleted**: if some website content can be found multiple times in all the webpages of one company, then it is skipped. *Example*: undesired and redundant lines like \"Contact Us\" are removed, ensuring that the final content does not include unnecessary sentences.\n- **Caching of already downloaded pages**: for each webpage, the content is stored in a JSON file, as well as the found sublinks. *Example*: after a run with a limit of N pages, other runs with less than N pages will use the stored files instead downloading data from internet; at the contrary, if the limit is increased to M > N pages, only M - N additional pages will be downloaded while the first N pages will be taken from the stored file.","metadata":{}},{"cell_type":"markdown","source":"## Load the results from the crawler's repo","metadata":{}},{"cell_type":"code","source":"github_downloader.download_files_from_github_repo(folderName=\"\", saveFolder=\"/kaggle/working/companies_info\", extension=\"json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:18.905649Z","iopub.execute_input":"2024-11-22T23:13:18.905947Z","iopub.status.idle":"2024-11-22T23:13:19.473584Z","shell.execute_reply.started":"2024-11-22T23:13:18.905920Z","shell.execute_reply":"2024-11-22T23:13:19.472633Z"}},"outputs":[{"name":"stdout","text":"Downloading companies_info.json...\n/kaggle/working/companies_info/companies_info.json downloaded successfully.\nAll files downloaded.\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"Locate the JSON file containing the companies' information.","metadata":{}},{"cell_type":"code","source":"import os\n\n# if the JSON file is given as Kaggle Input (for example, manually uploaded), change the use_kaggle_input to True\nuse_kaggle_input_companies = False if os.path.exists('/kaggle/working/companies_info') else True\ncompanies_json_name = 'companies_info.json'\nif use_kaggle_input_companies:\n    companies_info_file_path = os.path.join('/kaggle/input/companies-info', companies_json_name)\nelse:\n    companies_info_file_path = os.path.join('/kaggle/working/companies_info', companies_json_name)\n\nprint(f\"The file {companies_info_file_path} will be used for the information regarding the companies\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:19.474813Z","iopub.execute_input":"2024-11-22T23:13:19.475082Z","iopub.status.idle":"2024-11-22T23:13:19.482030Z","shell.execute_reply.started":"2024-11-22T23:13:19.475055Z","shell.execute_reply":"2024-11-22T23:13:19.480525Z"}},"outputs":[{"name":"stdout","text":"The file /kaggle/working/companies_info/companies_info.json will be used for the information regarding the companies\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"Define a small function to read the information about the companies - in JSON format.","metadata":{}},{"cell_type":"code","source":"import json\n\ndef read_companies_info(jsonFilePath: str) -> dict:\n    if os.path.exists(jsonFilePath):\n        with open(jsonFilePath, \"r\") as f:\n            data = json.load(f)\n        return data\n    else:\n        return {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:19.483156Z","iopub.execute_input":"2024-11-22T23:13:19.483478Z","iopub.status.idle":"2024-11-22T23:13:19.495924Z","shell.execute_reply.started":"2024-11-22T23:13:19.483432Z","shell.execute_reply":"2024-11-22T23:13:19.494958Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"Load the companies' information by using the defined function.","metadata":{}},{"cell_type":"code","source":"companies_info = read_companies_info(companies_info_file_path)\n\n# companies_info is a dictionary, where the key is the name of the company and the related value its information\n# print(companies_info[\"SIEMENS\"]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:19.497009Z","iopub.execute_input":"2024-11-22T23:13:19.497284Z","iopub.status.idle":"2024-11-22T23:13:19.550409Z","shell.execute_reply.started":"2024-11-22T23:13:19.497260Z","shell.execute_reply":"2024-11-22T23:13:19.549468Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"# Chat with Gemini","metadata":{}},{"cell_type":"code","source":"# API key got here: https://ai.google.dev/tutorials/setup\n\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n\nuser_secrets = UserSecretsClient()\nsecret_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n\ngenai.configure(api_key = secret_key)\n\nmodel_name = 'gemini-1.5-flash-latest'\nmodel = genai.GenerativeModel(model_name=model_name)\n\nchat = model.start_chat()\n\nmodel_info = genai.get_model(f\"models/{model_name}\")\nprint(f\"{model_info.input_token_limit=}\")\nprint(f\"{model_info.output_token_limit=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:19.551525Z","iopub.execute_input":"2024-11-22T23:13:19.551830Z","iopub.status.idle":"2024-11-22T23:13:20.125857Z","shell.execute_reply.started":"2024-11-22T23:13:19.551802Z","shell.execute_reply":"2024-11-22T23:13:20.124998Z"}},"outputs":[{"name":"stdout","text":"model_info.input_token_limit=1000000\nmodel_info.output_token_limit=8192\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"## Define the system and user prompts","metadata":{}},{"cell_type":"code","source":"system_prompt = \"You are an experienced technical sales manager. You are given the full portfolio for products and solutions of companies, through their website. Use this information to provide detailed technical answers based on the tender requirements which were given to you.\"\n\nMarkdown(system_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:20.126993Z","iopub.execute_input":"2024-11-22T23:13:20.127255Z","iopub.status.idle":"2024-11-22T23:13:20.133203Z","shell.execute_reply.started":"2024-11-22T23:13:20.127229Z","shell.execute_reply":"2024-11-22T23:13:20.132328Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"You are an experienced technical sales manager. You are given the full portfolio for products and solutions of companies, through their website. Use this information to provide detailed technical answers based on the tender requirements which were given to you."},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"tender_prompt_template = \"The document you have is a tender, that contains technical requirements for a project. Summarize the technical requirements. The content of the document is: \"\ntender_prompts = []\nfor info in tenders_info.values():\n    tender_prompts.append(f\"You have a document called {info['name']} . \" + tender_prompt_template + f\"{info['content']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:20.135853Z","iopub.execute_input":"2024-11-22T23:13:20.136099Z","iopub.status.idle":"2024-11-22T23:13:20.143259Z","shell.execute_reply.started":"2024-11-22T23:13:20.136057Z","shell.execute_reply":"2024-11-22T23:13:20.142484Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"user_prompt = f\"\"\"\n\n1. Identify all the technical requirements in the tenders' information you have.\n\n2. For company [SIEMENS] and [HITACHI], find the respective relevant products and solutions with respect to point 1. Do this one company at a time and store the results.\n\n3. Calculate an affinity score in percentage of company [SIEMENS] and [HITACHI] based on the match of results in point 2. Explain the way how you computed this percentage.\n\nSIEMENS: {companies_info[\"SIEMENS\"]}\nHITACHI: {companies_info[\"HITACHI\"]}\n\n4. Return a quick technical summary of the tender.\n\n5. Return the technical details of the company with the highest affinity score and its score. Focus on the technical specifications mentioning the compliances with the tender. Report also the URL of the source where you found the informations and mention if there is some non compliant requirements from tender.\n\n6. Return also the other affinity scores alone of the other companies. \n\n\"\"\"\n\n# Markdown(user_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:20.144235Z","iopub.execute_input":"2024-11-22T23:13:20.144798Z","iopub.status.idle":"2024-11-22T23:13:20.157947Z","shell.execute_reply.started":"2024-11-22T23:13:20.144761Z","shell.execute_reply":"2024-11-22T23:13:20.157248Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"## Analyze all the tenders","metadata":{}},{"cell_type":"code","source":"from time import sleep\n\nwant_a_response = True # disable if willing to save a notebook but the Gemini quota has been exhausted\n\nresponses = []\nif want_a_response:\n    num_queries = 0\n    for tender_prompt, tender_name in zip(tender_prompts, tenders):\n        print(f\"Generating response for tender {tender_name} ...\")\n        response = chat.send_message(tender_prompt)\n        # print(response.text)\n        responses.append((tender_prompt, response.text, response.usage_metadata))\n        print(f\"Response for tender {tender_name} generated.\")\n\n        num_queries += 1\n        \"\"\"\n        if num_queries % 2 == 0:\n            wait_time_seconds = 90\n            print(f\"Waiting {wait_time_seconds} before continuing, to not exceed Gemini's quota\")\n            sleep(wait_time_seconds)\n        \"\"\"\n\n    print(\"Analysis of the tenders concluded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:20.159017Z","iopub.execute_input":"2024-11-22T23:13:20.159333Z","iopub.status.idle":"2024-11-22T23:13:36.394184Z","shell.execute_reply.started":"2024-11-22T23:13:20.159297Z","shell.execute_reply":"2024-11-22T23:13:36.393279Z"}},"outputs":[{"name":"stdout","text":"Generating response for tender tender_solar.pdf ...\nResponse for tender tender_solar.pdf generated.\nGenerating response for tender tender_wind.pdf ...\nResponse for tender tender_wind.pdf generated.\nAnalysis of the tenders concluded!\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# example how to include the chat history here https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_chat.ipynb\n# description of the Content class here https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai/GenerativeModel.md\nfrom google.generativeai.protos import Content, Part\n\nhistory_chat = []\nfor idx_response, response in enumerate(responses):\n    query = Part()\n    query.text = response[0]\n    # TODO: consider different users? Example: for the tender number idx_response, use f\"user_{idx_response}\"\n    history_chat.append(Content(role=\"user\", parts=[query]))\n\n    answer = Part()\n    answer.text = response[1]\n    history_chat.append(Content(role=\"model\", parts=[answer]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:36.395525Z","iopub.execute_input":"2024-11-22T23:13:36.396302Z","iopub.status.idle":"2024-11-22T23:13:36.401578Z","shell.execute_reply.started":"2024-11-22T23:13:36.396262Z","shell.execute_reply":"2024-11-22T23:13:36.400715Z"}},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":"## Test the history","metadata":{}},{"cell_type":"code","source":"chat_with_memory_temp = model.start_chat(history=history_chat)\nresponse_temp = chat_with_memory_temp.send_message(\"What are the tenders you have about?\")\n\nMarkdown(response_temp.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:36.402565Z","iopub.execute_input":"2024-11-22T23:13:36.402853Z","iopub.status.idle":"2024-11-22T23:13:39.353202Z","shell.execute_reply.started":"2024-11-22T23:13:36.402828Z","shell.execute_reply":"2024-11-22T23:13:39.352380Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I have access to information from two tender documents: one for a solar power plant project and one concerning wind energy projects.\n\nThe **solar power plant tender** detailed technical specifications for the construction of a 200 kWp solar PV plant, including a mini-grid.  This encompassed everything from the solar panels themselves and their mounting structures to the inverters, batteries, diesel generator backup, electrical cabling and infrastructure,  monitoring systems, building construction, and after-sales service.  The tender clearly outlined required specifications and standards for each component.\n\nThe **wind energy tender** document was more of a policy analysis and review of different tendering schemes for wind energy projects.  It did not present a single project tender but instead discussed various approaches to designing tenders for both onshore and offshore wind farms across different countries. The focus was on analyzing successful and unsuccessful elements of past tender designs, including different price-setting mechanisms, pre-qualification criteria, penalty systems, and the overall impact on project delivery rates and costs.  It offered a comparative analysis of best practices and pitfalls in various national tender programs.\n"},"metadata":{}}],"execution_count":66},{"cell_type":"markdown","source":"## Count the needed tokens","metadata":{}},{"cell_type":"code","source":"print(f\"{model.count_tokens(history_chat)=}\")\nprint(f\"{model.count_tokens(system_prompt + user_prompt)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:13:39.355223Z","iopub.execute_input":"2024-11-22T23:13:39.355463Z","iopub.status.idle":"2024-11-22T23:13:45.399434Z","shell.execute_reply.started":"2024-11-22T23:13:39.355439Z","shell.execute_reply":"2024-11-22T23:13:45.398471Z"}},"outputs":[{"name":"stdout","text":"model.count_tokens(history_chat)=total_tokens: 20606\n\nmodel.count_tokens(system_prompt + user_prompt)=total_tokens: 645265\n\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## Generate a response with chat history","metadata":{}},{"cell_type":"code","source":"if want_a_response:\n    chat_with_memory = model.start_chat(history=history_chat)\n    \n    print(\"Providing prompts based on the previous analysis of the tenders ...\")\n    response = chat_with_memory.send_message(system_prompt + user_prompt)\n    # print(response.text)\n    responses.append((system_prompt + user_prompt, response.text, response.usage_metadata))\n\n    print(\"Response to the prompts is ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:16:34.991119Z","iopub.execute_input":"2024-11-22T23:16:34.991502Z","iopub.status.idle":"2024-11-22T23:17:19.594690Z","shell.execute_reply.started":"2024-11-22T23:16:34.991470Z","shell.execute_reply":"2024-11-22T23:17:19.593392Z"}},"outputs":[{"name":"stdout","text":"Providing prompts based on the previous analysis of the tenders ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[69], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m chat_with_memory \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstart_chat(history\u001b[38;5;241m=\u001b[39mhistory_chat)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProviding prompts based on the previous analysis of the tenders ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_with_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(response.text)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m responses\u001b[38;5;241m.\u001b[39mappend((system_prompt \u001b[38;5;241m+\u001b[39m user_prompt, response\u001b[38;5;241m.\u001b[39mtext, response\u001b[38;5;241m.\u001b[39musage_metadata))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:578\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n\u001b[0;32m--> 578\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/client.py:260\u001b[0m, in \u001b[0;36m_ClientManager.make_client.<locals>.add_default_metadata_wrapper.<locals>.call\u001b[0;34m(metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39margs, metadata\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    259\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata)\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n","\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."],"ename":"ResourceExhausted","evalue":"429 Resource has been exhausted (e.g. check quota).","output_type":"error"}],"execution_count":69},{"cell_type":"markdown","source":"## Check how many tokens have been used so far","metadata":{}},{"cell_type":"code","source":"if want_a_response:\n    tot_tokens = 0\n    for idx_response, response in enumerate(responses):\n        response_token = response[2].total_token_count\n        print(f\"Token count for response {idx_response}: {response_token}\")\n        tot_tokens += response_token\n\n    print(f\"Total number of tokens: {tot_tokens}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:15:12.484616Z","iopub.status.idle":"2024-11-22T23:15:12.484962Z","shell.execute_reply.started":"2024-11-22T23:15:12.484813Z","shell.execute_reply":"2024-11-22T23:15:12.484830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if responses:\n    print(responses[-1][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T23:15:12.486109Z","iopub.status.idle":"2024-11-22T23:15:12.486389Z","shell.execute_reply.started":"2024-11-22T23:15:12.486249Z","shell.execute_reply":"2024-11-22T23:15:12.486262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}